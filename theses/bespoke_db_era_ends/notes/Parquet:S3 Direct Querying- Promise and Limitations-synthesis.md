The sources present a nuanced picture regarding the state and capabilities of direct querying on Parquet/S3, highlighting both its burgeoning dominance and its existing limitations.

### Direct Querying on Parquet/S3 is Widespread, Effective, and Often Preferred

One perspective emphasizes that direct querying on Parquet/S3 is rapidly becoming the **default and preferred method for analytical workloads** in modern data architectures. A significant and growing majority of organizations, including large enterprises, are now running **over half of their analytics workloads on a "data lakehouse"**, which fundamentally relies on object storage with SQL engines instead of loading data into traditional databases. The sheer scale of adoption is evident in metrics like Amazon Redshift customers scanning **over 77 exabytes of data directly from S3** in 2024 alone, indicating it's a mainstream, not niche, practice. This approach is favored because it **eliminates costly data movement and duplication**, unifies data access across various tools, and allows independent scaling of compute and storage for better cost efficiency and flexibility. Furthermore, modern engines (like Trino) running on these open formats can offer **comparable or even faster performance** than traditional solutions for many SQL queries.

**Strongest Citations for this side:**
*   "65% of IT/data professionals reported that **over half of their analytics workloads are running on a “data lakehouse”** – i.e. using object storage with SQL engines rather than loading data into a traditional database."
*   "Amazon Redshift users collectively scanned **over 77 exabytes of data directly from data lake storage** (S3) via Redshift Spectrum and related features."
*   "The **“lakehouse” architecture – combining cloud storage with open formats and multiple query engines – is increasingly the default** for new analytics platforms, often supplementing or even replacing traditional warehouses."

### Limitations and Challenges of Direct Querying on Parquet/S3

Conversely, the sources also point out that direct querying on Parquet/S3, while promising, faces **significant limitations and has not yet fully replaced traditional data warehouses**. Many organizations, even those exploring lakehouses, still maintain a **two-tier architecture** with a data lake for raw storage and a warehouse for curated data. A key challenge lies in **performance for concurrent, low-latency BI queries**, where traditional warehouses with their sophisticated optimizers and caching still **outperform direct queries on object storage**, potentially leading to slower dashboards and diminished usability. The **maturity of the tooling and ecosystem** for storage-centric approaches is also a concern, as there's a **lack of a clear, vendor-agnostic definition for "lakehouse"** and ongoing "table format wars" (Iceberg vs. Delta vs. Hudi) which cause hesitation. This leads many organizations to **only pilot these formats** rather than rolling them out company-wide, indicating that the shift is still in early stages and **not yet the universal default**.

**Strongest Citations for this side:**
*   "data lakehouse is still not mature enough to fully replace a data warehouse. Snowflake, Redshift and BigQuery are still used a lot. Two-tier architecture (data lake + data warehouse) is also quite common."
*   "query engines on object storage, like Trino/Presto or Spark, can struggle with **concurrent low-latency queries** that data warehouses handle gracefully. As one practitioner put it, queries can “take a bit too long and usability suffers if you’re using something like Trino/Dremio/Athena directly on top of object storage without a little aggregation” for BI dashboards."
*   "Apache Iceberg... is still at an early stage…with competing technologies trying to get momentum too” ... “most organizations are still evaluating, not adopting these table formats in production across the organization yet."