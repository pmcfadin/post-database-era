Unified Multi-API Data Gateway Prevalence in Managed DB Platforms (2025–2030)

Executive Summary

Overview: Unified multi-API data gateways – i.e. database platforms that support multiple data models or API interfaces within one integrated system – are emerging as a significant trend in data management. This report examines their prevalence among top managed database platforms, adoption in new products, customer usage patterns, impact on vendor revenue, and recognition by industry analysts through 2030. It also provides future predictions and addresses counter-evidence and skepticism.

Key Findings: By 2025, only a minority of leading database services offered a unified multi-model API gateway out-of-the-box, but this is changing rapidly. Industry research indicates multi-model databases are among the fastest-growing categories ￼. Gartner projected that by 2025 over 50% of enterprise data initiatives would leverage multi-model capabilities ￼, signaling accelerating adoption. New database platform launches in the 2020s increasingly include multi-API support by default (e.g. Azure Cosmos DB, Oracle Autonomous DB, Couchbase Capella), rather than as optional add-ons – an estimated two-thirds of new DB products now emphasize multi-model functionality from the start. In contrast, older single-model databases (and vendors like AWS with “purpose-built” one-model-per-service approaches) have been slower to unify APIs.

Customer Adoption: Where multi-API gateways are offered, uptake is growing but not yet universal. Many customers still use single-model modes initially, but a substantial segment is taking advantage of unified gateways. For example, Azure Cosmos DB users can choose SQL, MongoDB, Cassandra, Graph, or Table APIs on the same back-end, and its MongoDB-compatible API has attracted many developers (indicating significant use of the multi-API feature) ￼. Similarly, DataStax’s Astra DB (Cassandra) reports strong interest in its Stargate API gateway for GraphQL/REST access. However, exact percentages per vendor are not publicly disclosed in available sources – we did not find precise per-vendor figures. Estimates suggest that as of mid-2025 perhaps ~20–30% of customers actively leverage the multi-API capabilities when available, with that share expected to rise toward a majority by 2030 as multi-model becomes mainstream ￼.

Purchase Drivers: Multi-API support is increasingly cited as a key purchase driver in case studies, though usually alongside other factors (performance, scalability, cost). Notably, some organizations chose a platform specifically to avoid managing multiple specialized databases. For example, a case study on ArangoDB (a native multi-model DB) shows the CTO consolidated search, graph, and document stores into one system – “we’ve consolidated all … search, graph and document data stores into ArangoDB… it’s accelerated our performance because now we do not need to learn multiple technologies” ￼. Likewise, Couchbase’s multi-model features enabled Domino’s to handle operational transactions, full-text search, and analytics in one database, which was a significant benefit ￼. Such examples demonstrate multi-API gateways can be the primary or an important reason for selecting a platform, though in most cases it’s one of several drivers rather than the sole factor.

Revenue Impact: Revenue attributable to multi-API database offerings is growing for vendors, but specific breakdowns are rarely public. Many leading vendors have folded multi-model into their flagship products (e.g. Oracle’s converged database, Microsoft Azure’s Cosmos DB) rather than selling it as a separate SKU, making direct revenue attribution difficult. Niche multi-model database providers derive essentially 100% of their revenue from multi-API platforms (e.g. Couchbase’s FY2023 $154.8M revenue was entirely from its multi-model NoSQL platform ￼). The NoSQL/multi-model database market overall is projected to surge from about $15 billion in 2025 to $55.5 billion by 2030 ￼ – a nearly fourfold increase, far outpacing general DB market growth – which implies multi-API offerings will account for a much larger share of industry ARR by 2030. By our analysis, multi-model and unified API-capable services could comprise over half of database platform revenues by 2030, up from perhaps ~10–20% in the mid-2020s, as cloud DBMS revenue shifts toward these modern offerings (for example, Oracle’s and Azure’s fastest-growing services are multi-model ￼). Analyst Outlook: By 2030, industry analysts are expected to formally recognize multi-API support as a standard capability. Already, Gartner’s evaluations note vendors’ “multimodel” features (e.g. calling Oracle Autonomous DB “a robust, multimodel database service designed for diverse workloads” in the 2024 Cloud DBMS Magic Quadrant ￼). It’s anticipated that future MQs and Waves will explicitly list multi-model API support as a key criterion or assume its presence in leading platforms, reflecting its mainstream status.

Predictions: From 2025 to 2030, unified multi-API gateways will shift from a niche differentiator to a default expectation in database platforms. We predict that by 2030, 70%+ of top managed DB platforms will natively ship with multi-API (multi-model) capabilities enabled, and most new database products will be “multi-model by default.” Customers will increasingly demand this flexibility – enabling use of document, graph, relational, key-value, etc. under one service – to simplify architectures and avoid data silos. Analyst tracking will likewise evolve, with “multi-model” or “unified API” support becoming an assumed checklist item for any leading DBMS. However, specialized single-model databases will not disappear; they will continue in specific high-performance niches or as part of polyglot strategies where needed (see Counter-Evidence). On balance, the trajectory points to a future where multi-API data gateways are ubiquitous in database platforms, driving both product strategy and how organizations manage data.

Introduction: The Rise of Unified Multi-API Gateways

Modern applications deal with an unprecedented diversity of data: relational tables, JSON documents, graph relationships, geospatial data, time-series streams, etc. ￼ ￼. Traditionally, handling such variety meant deploying multiple specialized databases – a polyglot persistence approach with separate SQL, NoSQL, and analytic systems ￼. This introduces complexity in integration, consistency, and operations ￼. Unified multi-API gateways (often realized as multi-model databases) have emerged to address these pain points. A multi-model DBMS supports two or more data models under one backend, exposing multiple query APIs or languages on the same data ￼. For example, a single service might offer SQL queries, MongoDB API calls, Gremlin graph traversals, and key-value access, all backed by one engine.

Notable early entrants in this category include Microsoft Azure Cosmos DB, which from its 2017 launch supported document (SQL), MongoDB, Cassandra, Table (key-value), and Gremlin (graph) APIs on a globally-distributed backend ￼. Other examples are ArangoDB and OrientDB (open-source multi-model databases supporting document+graph+key-value in one engine) ￼, MarkLogic (enterprise multi-model DB with JSON, XML, and RDF graph), Couchbase (which added SQL-for-JSON, full-text search, and analytics atop a key-value store), and Oracle Database, which evolved into a “converged” multi-model database (relational with native JSON, XML, spatial, graph, etc.). These platforms provide a unified gateway to access different data formats and models without moving data between separate systems.

Benefits: Unified multi-API gateways promise several advantages. They can reduce data redundancy and siloing by storing varied data in one system ￼ ￼. They simplify development and operations – teams deal with one platform, one security and governance model, and can join across data model boundaries ￼ ￼. Organizations report faster development iterations and lower TCO by consolidating databases ￼ ￼. For instance, developers don’t need to use multiple query languages and drivers; a unified query engine can retrieve both graph and document data in one shot ￼ ￼. A Gartner-cited study noted companies using multi-model solutions saw a 40% reduction in time spent on data management tasks ￼. This flexibility and agility align well with modern microservices and cloud-native architectures.

Challenges: There are also challenges. Multi-model systems can be complex to engineer and may not always match a dedicated system’s performance for a specific model ￼ ￼. Some DBMSs introduced multi-model features that customers didn’t immediately adopt if existing solutions sufficed. As we discuss later in Counter-Evidence, some industry players argue that “one size fits all” databases can compromise on specialized needs ￼. Despite this, the general trend in the data platform market is toward greater unification of capabilities to meet evolving demands.

This report delves into six sub-questions around this trend, providing data and predictions for the period 2025 to 2030 on how prevalent unified data gateways will become, how they’re being adopted, and how the industry perceives them.

Prevalence Among Top Managed DB Platforms (2025 → 2030)

Current State (2025): As of the mid-2020s, unified multi-API gateways are present in a significant minority of top managed database services, but not the majority – yet. Out of the leading cloud DB platforms, only some offered true multi-model support out-of-the-box. For example, Azure Cosmos DB is explicitly multi-model (five APIs) and Oracle Autonomous Database supports multiple data types in one engine (relational, JSON, spatial, graph, etc.), as does SAP HANA and IBM Db2 to a degree. Several newer distributed databases like YugabyteDB (which exposes both PostgreSQL and Cassandra APIs on one back-end) and Fauna (custom query language + native GraphQL API) were built with multi-API from the ground up. On the other hand, the largest provider, AWS, pursued a different approach by offering separate purpose-built databases (Aurora for SQL, DynamoDB for NoSQL, Neptune for graph, etc.) with no unified gateway – meaning AWS’s platform did not ship a single multi-API engine, but rather many single-model services. Other popular databases like PostgreSQL, MySQL, MongoDB (Atlas), and Neo4j remained primarily single-model (though some had extensions for JSON or GraphQL, they aren’t unified multi-model engines in the same sense).

Industry analysts have observed that multi-model databases “have established themselves among the fastest-growing database categories” ￼, even if traditional single-model systems still dominate in absolute usage. A 2025 analysis by Gartner (cited in MoldStud Research) predicted that over half of new enterprise data projects would leverage multi-model capabilities by that year ￼. This suggests that among new adoptions the scales are already tipping toward unified solutions, even if legacy deployments skew the installed base. In terms of vendors: we estimate roughly 20–30% of the “top” managed DB platforms in 2025 (considering top 10–15 services by popularity or cloud market share) offered a unified multi-API gateway. This includes the likes of Cosmos DB, Oracle’s Autonomous DB, Couchbase Capella, etc. – but many others did not (e.g., AWS’s popular RDS/Aurora and DynamoDB, Google Cloud Spanner/Firestore, MongoDB Atlas, etc., were single-model oriented).

Emerging Trend: The trajectory toward 2030 is for much broader adoption of multi-model capabilities in leading platforms. Experts envision a future where most database services are multi-model in nature, potentially making the term “NoSQL” obsolete as distinctions blur ￼. In Rapydo’s forward-looking analysis, the author predicts that by the 2030s, even stalwarts like MySQL and Postgres will likely have evolved into highly multi-model systems ￼ ￼. This indicates an expectation that multi-API support becomes mainstream in essentially all major DBMS.

Prediction (2030): We project that by 2030, a majority (perhaps ~70% or more) of the top managed database platforms will ship with unified multi-API gateways baked in. Many single-model services today will either add support for additional APIs/models or be succeeded by new offerings that are multi-model. For instance, one can envision AWS eventually introducing more integration (even if via behind-the-scenes links) to offer unified access – pressure from the market might drive even the purpose-built camp to provide a more unified developer experience. Already, multi-model databases are becoming a competitive differentiator. A list of top multi-model databases in 2024 included MarkLogic, ArangoDB, OrientDB, Azure Cosmos DB, FoundationDB, Couchbase, and Apache Ignite ￼ – a mix of incumbents and upstarts. By 2030, such capabilities may be ubiquitous among leaders rather than limited to a subset.

It’s also likely that new database growth will largely be in cloud-native, multi-model services. Cloud adoption is driving innovation faster (with 91% of new databases deployed in cloud environments as of 2024 ￼), and cloud DBaaS providers iterate quickly on features. Many vendors are indeed introducing new features in cloud-first, including multi-model support, then back-porting on-premises ￼. Given this, our outlook is that virtually every major cloud database service launched by 2030 will consider multi-API support a core requirement, making unified gateways prevalent.

To summarize, current prevalence is limited (with notable examples, but not universal), whereas by 2030 we anticipate unified multi-API gateways to be commonplace among top platforms, reflecting their fast-growing importance in the market ￼ and the move toward multi-model mainstream acceptance ￼.

(Sources: Gartner and industry research indicate multi-model DBs are among the fastest-growing categories ￼. By 2025 over half of enterprise data initiatives use multi-model tech ￼, pointing to much wider adoption by 2030. Azure’s Cosmos DB and Oracle’s multimodel DB exemplify current leaders with unified APIs ￼ ￼.)

Inclusion in New Platform Launches: Default vs. Add-On

A clear trend in recent years is that new database platforms tend to launch with multi-API support built-in (“default”) rather than treating it as an optional afterthought. In contrast, older platforms have sometimes retrofitted multi-model capabilities as add-ons or extensions.

New Launches (2020–2025): Many of the notable database releases or major version revamps in this period have touted multi-model or multi-API capabilities from day one. For example, Azure Cosmos DB was designed from inception to support multiple APIs under a single service (document, graph, etc.) ￼. YugabyteDB launched with both SQL (PostgreSQL) and NoSQL (Cassandra) query interfaces by default. FaunaDB (a cloud database launched in late 2010s) introduced a native GraphQL API in addition to its custom query language, effectively offering multi-API access. ArangoDB has been multi-model since its first release (supporting documents, graphs, key-value). Couchbase evolved its architecture early on (mid-2010s) to integrate a SQL-based query for JSON and full-text search into its key-value engine – by the time it launched its cloud DBaaS “Capella,” multi-model (document + key-value + search) was a core feature, not an add-on. Snowflake, while primarily an analytic SQL database, added support for unstructured data and even Python execution; and though not a classic multi-model OLTP engine, it indicates new platforms expanding interface capabilities. Another example is Google’s AlloyDB (launched 2022) – while based on PostgreSQL (SQL), Google has been adding features like document JSON support and hints of integrating ML/Graph, trending toward multi-model. We can also point to emerging projects like SurrealDB (announced as a “multi-model” NewSQL database with graph and document support) ￼.

A research list of Top Multi-Model Databases in 2024 underscores that many contemporary systems are multi-model: “MarkLogic, ArangoDB, OrientDB, Azure Cosmos DB, FoundationDB, Couchbase, Apache Ignite” are highlighted ￼. Notably, these are all either relatively new or significantly re-engineered platforms. This indicates that most new entrants see multi-model support as a selling point and include it by default.

Add-On Approaches: In contrast, some established databases added multi-model features as optional modules or companion services. For example, Apache Cassandra (born 2008) was originally a pure wide-column NoSQL store; the vendor DataStax later provided “DSE Search” and “DSE Graph” as add-ons to give Cassandra full-text search and graph capabilities, and more recently the open-source Stargate gateway was introduced to add REST and GraphQL APIs on top of Cassandra ￼. These are effectively bolt-ons to an existing engine. Redis is another example – initially a key-value cache, it gained a JSON document module, a Graph module, etc., which a user can opt to enable. PostgreSQL and MySQL added JSON data type support and even GIS/spatial extensions over time, but those were incremental, not a unified multi-model rewrite (and using a JSON field in MySQL is optional; many deployments don’t use it). MongoDB has remained a document database at core, but via its Atlas platform it offers additional interfaces (Atlas Search, Realm GraphQL, etc.) – again as additional services on top of the core engine.

What share of new platforms are multi-API by default vs. add-on in recent times? While exact numbers are hard to quantify, qualitatively the majority of new general-purpose databases lean multi-model. A Gartner report noted that by 2025 “over half of enterprise data initiatives will leverage multi-model capabilities” ￼, implying that new projects (which often choose new platforms) favor multi-model solutions. We can interpret that as >50% of newly adopted platforms likely include multi-API features out-of-the-box (since those initiatives wouldn’t leverage multi-model if the chosen software didn’t provide it). Additionally, a DB-Engines survey cited in 2024 found 43% of companies considered schema flexibility (a hallmark of multi-model JSON support) a critical factor in selecting a DBMS ￼. This shows that new platform selection criteria are aligned with multi-model capabilities, which new offerings are keen to provide inherently.

Our assessment is that as of 2025, roughly 60–70% of new database platforms (either newly launched products or major new cloud DB services) come with multi-API/multi-model support by default. The remainder that do not are often specialized (e.g., pure time-series databases, or pure vector databases for AI which focus on one model due to early stage focus). By 2030, we expect this to approach ~90-100%: essentially all serious new entrants in the DBMS space will be multi-model from the start, because by then supporting multiple data types and access patterns will be viewed as a must-have for broad market appeal.

Another angle is new feature launches on existing platforms: many vendors are turning previously add-on capabilities into built-in defaults. For instance, Microsoft could have kept graph support as separate (it introduced graph extensions in Azure SQL Database), but instead is integrating these into core offerings. Oracle has made nearly all its multi-model features part of the core database license by 19c/21c (graph and JSON are included). That indicates even when not “new platform” per se, the product evolution is toward bundling multi-model as default rather than charging extra.

In summary, the share of new platform launches with multi-API by default has overtaken those requiring add-ons. Since 2020, the industry has shifted such that multi-model is a baseline design goal for new DBMS products. This is only expected to strengthen towards 2030, effectively making add-on approaches rare. The older notion of a single-model database that needs bolt-on plugins to handle other data is falling out of favor, as customers prefer integrated solutions that “allow seamless integration and querying of different types of data within a single unified framework” ￼.

(Sources: Many top new databases of recent years are multi-model by design ￼. Gartner notes 50%+ of new data initiatives use multi-model tech by 2025 ￼. Companies report multi-model adoption rising ~30% in just three years ￼, reflecting new platforms driving this.)

Customer Adoption: Multi-API Gateway Usage vs. Single-API

A critical question is how many customers that have the option of a unified multi-API gateway actually use it, versus sticking to a single API or data model. In other words, for vendors that offer both multi-model capabilities and single-model modes, what percentage of their customers enable or utilize the multi-API features?

Observations: Direct statistics per vendor are scarce (and no specific breakdown was found in connected sources for any major vendor on this metric). However, some insights can be inferred:
	•	Azure Cosmos DB: This service requires users to choose an API when creating a database account (e.g. Core SQL API, MongoDB API, Cassandra API, etc.). The popularity of the Cosmos MongoDB API suggests many customers are leveraging Cosmos specifically for a non-SQL API – essentially using the multi-model capability to adopt Cosmos as a substitute for MongoDB (document store) with Azure’s global distribution. Microsoft has hinted that the Mongo API is a significant fraction of Cosmos usage. While exact numbers aren’t published, it’s believed a large portion (possibly a majority) of Cosmos DB customers opt for the MongoDB API or other APIs rather than the native SQL API – indicating the multi-API gateway feature is heavily used. In any case, 100% of Cosmos DB customers have technically enabled one of the multi-APIs (since Cosmos is multi-model by nature, every account uses at least one API). The key question is how many use multiple APIs or switch among them; that might be more limited due to each database instance focusing on one API at a time.
	•	Oracle Database: Oracle’s converged database has all data models in one engine. Nearly all Oracle customers have the multi-model features available (JSON, XML, Spatial, Graph, etc.), but not all actively use all of them. For instance, many Oracle deployments might use it just as a relational store + some JSON, never touching the graph feature. Oracle hasn’t broken out how many clients use multi-model capabilities extensively. Since Oracle doesn’t sell separate “single-model” SKUs (it’s all one product now), adoption is more about feature usage. Anecdotally, JSON usage in Oracle and SQL Server has grown immensely as apps store semi-structured data; graph usage is smaller but growing for things like fraud detection. One could speculate that by 2025 perhaps 20–30% of Oracle customers were using non-relational features (like JSON or spatial) regularly, and this could climb toward the majority by 2030 as these features become standard practice.
	•	MongoDB Atlas: Atlas is mainly a document DB cloud service, but it offers Realm/App Services which include GraphQL and REST APIs to Mongo data. MongoDB has encouraged developers to use its Realm GraphQL for easier app dev. We don’t have a percentage, but given MongoDB’s focus remains on the core document model, likely a smaller share of Atlas customers actively use the GraphQL/Realm features (maybe in the tens of percent or less as of mid-2020s). MongoDB’s CEO has mentioned increased interest in Realm, but no concrete numbers. By 2030, if GraphQL becomes ubiquitous, a larger portion might use that API.
	•	Cassandra/DataStax: With the introduction of Stargate in Astra DB (DataStax’s cloud Cassandra), users can choose to interact via CQL (Cassandra’s native query language) or via REST/GraphQL/gRPC through Stargate. Initially, many longtime Cassandra users stick to CQL, but new adopters (developers building microservices, for example) are quite keen on GraphQL and REST for ease. DataStax has noted that making Cassandra easier with these APIs is key to onboarding new users ￼. While we have no ratio published, we can imagine in the early phase maybe ~10–20% of Astra DB customers were primarily using the Stargate APIs (with the rest using CQL). This is expected to grow as Stargate matures.
	•	Couchbase: Couchbase doesn’t have separate SKUs; every Couchbase deployment can use key-value, query (SQL++), full-text search, etc. According to Couchbase’s marketing, customers commonly use it to replace multiple systems (caches, search engines, and DBs) ￼ ￼. A case study mentioned that Domino’s Pizza could do search and transaction processing in one Couchbase cluster due to its multi-model capabilities ￼. We can infer that a significant share of Couchbase customers (especially the large ones) are using more than one service (e.g. both the caching and the query engine). In one Couchbase survey, many clients cited the flexibility of JSON + SQL as a reason for choosing it. So likely a majority of Couchbase deployments use its query service (N1QL) on JSON documents – which is using the multi-model aspect (key-value + JSON query). Fewer might use full-text search or analytics services unless needed. Still, enabling those is straightforward since it’s one platform.
	•	Multi-Model Specialists: For databases that are inherently multi-model (ArangoDB, MarkLogic, etc.), essentially 100% of their customers bought it for that reason and presumably use multiple models. MarkLogic users often use both document and semantic graph features. ArangoDB users often execute graph traversals and also store document collections – that’s the whole point of choosing it. So in those cases, “customers enabling the gateway vs single-API” isn’t a split – they all have it enabled by virtue of using the product.

From these points, a general pattern emerges: In platforms where multi-API is optional, initial adoption was modest but growing. As of ~2025 perhaps a minority (20–40%) of customers in those ecosystems actively take advantage of the multi-model features, with the rest using the platform in a more limited (single-model) way. But this minority is expanding. By 2030, we anticipate that for most vendors offering multi-API, the majority of their customers will be using at least some of those multi-model capabilities. This is supported by the overall trend of multi-model adoption: surveys showed a 30% increase in multi-model solution adoption over three years ￼ and report that over 50% of enterprises integrated such technologies and achieved cost reductions ￼, meaning more organizations are operationalizing those features. As multi-API gateways become more standard and easier to use, customers will naturally “flip the switch” to use them.

Another factor is that many cloud databases handle the complexity under the hood – customers might be using a multi-model service without thinking of it as such. For example, if an Azure Cosmos DB user picks the MongoDB API, they might consider it “I’m using MongoDB-as-a-service,” not necessarily “I’m using a multi-API platform,” but in effect they are leveraging the unified gateway (since Cosmos’s engine is abstracting the API differences). So usage could be undercounted if one only looks at those consciously using multiple interfaces.

In summary, precise per-vendor percentages are not published (we did not find hard stats in sources), but evidence suggests growing utilization of multi-API gateways by customers. We estimate a significant minority in mid-2020s (perhaps one-third) and projecting a majority by 2030 for platforms where it’s available. This is bolstered by case studies and surveys demonstrating tangible benefits when customers do embrace the multi-model features (faster development, cost savings, etc.), which will encourage more to do so ￼ ￼.

(Sources: Gartner/MoldStud note 75% of organizations use a mix of data stores, indicating demand for unified solutions ￼. Over half of enterprises by 2025 leveraged multi-model tech ￼, suggesting many enabled those features. Azure Cosmos DB’s multi-API usage and Couchbase case studies show significant uptake ￼ ￼. Note: No connected source gave an exact “X% of vendor Y’s customers,” so the above is an analysis based on available qualitative info.)

Multi-API Gateway as a Purchase Driver (Case Studies)

Are unified multi-API gateways the primary reason customers choose a given database platform? In many cases, it appears to be an important factor, though often accompanied by other considerations. There are indeed public case studies and testimonials where multi-model capability is highlighted as a key driver of the decision.

A notable example is ArangoDB’s case study with Decoded Health (as quoted on ArangoDB’s site). The CTO describes how adopting ArangoDB allowed them to eliminate separate search, graph, and document databases, consolidating all those needs into one system – which drastically simplified their stack and improved performance. He stated: “we don’t have any other data storage mechanisms, we don’t have a search [engine]… we’ve consolidated all the services of search, graph and document data stores into ArangoDB… it’s accelerated our performance because now we do not need to learn multiple technologies.” ￼. This quote makes it clear that the unified multi-model nature of ArangoDB was a primary benefit and presumably a key reason they chose it (they explicitly valued not having to use multiple different databases).

Similarly, Couchbase has highlighted multi-model use cases in its customer stories. For instance, Domino’s Pizza’s adoption of Couchbase Server was partly driven by its ability to act as both an operational database and a full-text search engine in one. A Couchbase whitepaper notes that Domino’s leveraged Couchbase’s multi-model features to “process operational workloads, facilitate full text search, and analyze customer data within the same system.” ￼ All those capabilities in one platform meant Domino’s could avoid deploying separate systems for search vs. transactions vs. analytics. In effect, the multi-API gateway (Couchbase’s Query Service, Search service, etc. on the same data) was crucial to their architecture. We can infer that this versatility was a core reason for choosing Couchbase over other solutions.

Another case: Fidelity Investments chose Azure Cosmos DB for a globally distributed app – while the primary drivers cited were global scale and managed service benefits, Cosmos’s multi-model nature (support for diverse use cases) was an enabling factor ￼. In an Azure presentation, it was mentioned that “Fidelity chose Cosmos DB due to [..] global distribution, and ability to support multiple data models” ￼ (implying the multi-model aspect played a role, though perhaps not the singular driver).

MarkLogic customers (financial institutions, media companies integrating content, etc.) often point to the combination of document and semantic graph support as a reason they selected MarkLogic – effectively the ability to store JSON/XML and query relationships via SPARQL in one DB. For example, the U.S. healthcare.gov project famously used MarkLogic to unify disparate data sources; case studies mention flexibility of the multi-model DB in handling varied data. While performance and reliability were top criteria, the multi-model aspect was fundamental for meeting their integration needs.

OrientDB (another multi-model database) has case studies like Ericsson, which used it to handle both graph and document data for network inventory – they likely chose it over using a graph database plus a separate document store.

It appears that when organizations have a clear need for multiple data models (e.g. an application requires graph relationships and document storage, or needs both transaction and search capabilities), those that chose a multi-model platform often did so explicitly to avoid a multi-database solution. In such scenarios, the unified gateway is indeed the primary purchase driver. They might phrase it as choosing product X for its “flexibility” or “versatility”. For instance, Couchbase’s VP of Marketing noted customers say “I bought you for performance; I needed you for flexibility”, highlighting that beyond speed, the ability to replace other databases was a major draw ￼ ￼.

However, we should also note that not every case study will single out multi-API capability in isolation. Often, the story is that multi-model support combined with other benefits clinched the decision. For example, ArangoDB might also be chosen for its performance or lower TCO along with multi-model flexibility. Cosmos DB might be chosen for global scale and SLA, with multi-model being a supporting feature. Oracle may be chosen for enterprise features, with converged multi-model being part of the overall value.

In terms of numbers: there aren’t dozens of published case studies explicitly stating “we chose this DB primarily for its multi-model nature,” but there are at least a handful from different vendors: ArangoDB (as above), Couchbase (Domino’s, some IoT companies), MarkLogic (some government projects), etc. Many more case studies mention multi-model as a benefit even if not the headline.

Thus, the evidence suggests multi-API gateways are indeed a significant purchase driver for a non-trivial segment of customers, particularly those with complex data variety requirements. As the technology matures, vendors are actively promoting these success stories. By 2030, we expect to see many more case studies where companies cite “we consolidated from X separate databases down to one platform with multi-model support, which saved us time/money and enabled new capabilities” as a central narrative.

Currently, the count of publicly cited case studies focusing on this is limited. We did not find an exact count of such case studies across the industry in our sources – likely because they are spread across vendor websites and press releases. But qualitatively: every multi-model DB vendor has a few flagship stories (we’ve mentioned several), and even larger vendors like Microsoft/Oracle have references in conference talks to customers leveraging multi-model aspects as key enablers.

In summary, there are multiple public case studies that cite the unified multi-API capability as a primary or decisive factor in platform selection (examples: Decoded Health/ArangoDB ￼, Domino’s/Couchbase ￼, etc.). While not every customer needs that, for those that do, it’s often front and center in their rationale. We anticipate the number of such stories will grow as multi-API gateways become more common and more organizations realize the benefits of consolidation.

(Sources: ArangoDB case study quote – consolidation of search/graph/document was a game-changer ￼. Couchbase whitepaper – Domino’s using multi-model features for search + ops in one system ￼. These illustrate customers explicitly valuing the unified gateway. Many others cite flexibility/versatility (multi-model) as a key benefit alongside performance ￼.)

Revenue and ARR Attributable to Multi-API Offerings

As multi-API gateways become part of product offerings, a relevant question for vendors and investors is: how much revenue is tied to these multi-model capabilities? This can refer to either dedicated multi-model products’ revenue or the portion of a vendor’s total DB revenue that comes from multi-API-enabled SKUs versus single-model SKUs.

Current Snapshot: Many major database vendors have transitioned their portfolios such that their primary products are multi-model, making it difficult to delineate a separate revenue stream purely for “multi-API.” For example:
	•	Oracle: Oracle’s database revenue (on the order of ~$20+ billion annually in recent years) is now essentially all coming from what Oracle calls a “multimodel database” (Oracle Database 19c/21c). Oracle does not sell “single-model Oracle DB” – every Oracle DB license includes JSON, spatial, etc. So in a sense, close to 100% of Oracle’s database ARR is tied to a multi-model SKU (Autonomous Database, etc.). However, not all that revenue is driven by people using those features; it simply means the product is capable. Oracle’s emphasis on being a converged database suggests they believe this integrated approach is key to retaining and growing that revenue (and analysts see it as a strength in Gartner MQ reports ￼).
	•	Microsoft: Microsoft’s database portfolio includes Azure SQL (relational with some JSON/graph), Azure Cosmos DB (fully multi-model), and other Azure data services. Cosmos DB is a fully multi-API product; its revenue has been growing quickly, though Microsoft doesn’t break it out publicly. There have been hints that Cosmos DB, while not as large as Azure SQL yet, is a substantial and fast-growing service. If we estimate, Azure Cosmos DB could be a multi-hundred-million dollar business in 2025. Azure SQL’s revenue (including SQL Server on-prem and Azure SQL) is multi-billion, but primarily relational. So, for Microsoft, perhaps 10–15% of its overall DB revenue in 2025 is from explicitly multi-model services (Cosmos, maybe parts of Azure Data Explorer or others), but by 2030 this could increase if Cosmos (and similar services) outpace growth. Microsoft also added multi-model features to SQL (like graph support in SQL Server), but those didn’t generate separate SKU revenue – they just help defend SQL’s revenue.
	•	AWS: AWS’s approach means they don’t have one SKU that is multi-model; they have many purpose-built DB SKUs. So you’d have to combine revenue of multiple AWS services to consider “multi-model revenue.” AWS does not report individual service revenues either. We do know AWS database services as a whole (Aurora, RDS, DynamoDB, etc.) represent a significant portion of AWS’s ~$80B cloud revenue (with database being one of the largest PaaS segments for AWS). However, since AWS has not (yet) converged them, one could argue $0 is from a unified gateway (as they have none). Instead, AWS’s revenue is segmented: relational DB revenue, key-value DB revenue, etc. This is a counter-case: AWS bet that offering multiple single-model services would maximize revenue by capturing each use case separately, rather than a single multi-model offering.
	•	MongoDB Inc.: MongoDB’s Atlas revenue (~$400M+ in 2024, growing fast) is largely from its core document database service. Multi-API features like Realm are bundled in Atlas but not charged separately (except functions/calls usage possibly). So one might say virtually all of MongoDB’s revenue is still tied to its primary (document) API, even though they offer GraphQL as an accessory. If MongoDB introduced a new SKU or pricing for, say, using GraphQL or search, that could break out in the future.
	•	Specialized Multi-Model Vendors: For companies like Couchbase, MarkLogic, DataStax, etc., all their product revenue is effectively from multi-model databases:
	•	Couchbase (which is multi-model JSON+key-value) had $154.8M in total revenue for FY2023 ￼ – 100% tied to its multi-model DB platform (Capella or server).
	•	DataStax historically sold primarily Cassandra (single-model) but with DSE they added search/graph. Now their Astra DB (cloud) includes Stargate APIs. DataStax is private, but suppose their revenue is in the low hundreds of millions; an increasing portion of new bookings likely involve the Astra service with multi-API.
	•	MarkLogic (now part of Progress Software) might have tens of millions in revenue annually, all from its multi-model DB.
	•	ArangoDB is smaller but growing usage (often open-source with support subscriptions).

So, for these, essentially 100% of their ARR is “multi-model ARR,” since that’s their only product.

Analyst Market Estimates: Looking at industry-wide forecasts gives a sense of how multi-model revenue is growing relative to the market. The NoSQL database market, which overlaps heavily with multi-model (since many NoSQL are multi-model or being extended to be), is expected to climb from $15.04B in 2025 to $55.51B in 2030 (CAGR ~29.8%) ￼. That growth is much faster than the overall DBMS market (~10% CAGR) ￼. The strong growth indicates multi-model databases (often categorized under NoSQL/NewSQL) will capture an increasing share of spend. By 2030, that $55B might be nearly half of the total database market value at that time (the overall DB market maybe ~$130–150B by 2030) ￼. Similarly, cloud DBaaS is growing ~19% CAGR to $59B by 2030 ￼, and within cloud, multi-model services are among the key drivers (e.g. cloud-native JSON/NoSQL services growth outpaces traditional).

We can infer that by 2030, a substantial portion of database revenue (perhaps 50% or more) will be coming from products that are multi-API/multi-model. This doesn’t mean the other 50% disappears – relational single-model DBs will still have revenue (especially legacy on-prem). But new revenue and growth are disproportionately in multi-model offerings. For vendors, this means the slice of their ARR from multi-API capable products will be much larger in 2030 than today.

Vendor-Specific Projections:
	•	Microsoft: Cosmos DB could grow to be, say, 30–40% of Azure’s database services revenue by 2030 if trends continue, significantly upping multi-model’s share of Microsoft’s pie. Also Azure SQL likely gets more multi-model features (maybe integrated Cosmos APIs?).
	•	AWS: If AWS maintains separate services, it’s possible they still won’t have a single multi-model product by 2030, but they may start packaging them (for example, offering unified billing or tighter integration between DynamoDB, Neptune, etc.). AWS’s revenue tied to multi-model capability might remain “distributed” across services. However, if market pressure is high, AWS might introduce a new service that aggregates data models (this is speculative).
	•	Database startups that emphasize multi-API (Fauna, PlanetScale (which is looking at branching but not multi-model), etc.) will either grab some market or influence incumbents.
	•	Oracle: Oracle’s bet is that its converged DB keeps its customers from migrating to specialized solutions. If successful, Oracle retains its revenue and perhaps grows it via cloud adoption – all of which they will credit to having “all the capabilities in one engine” (multi-model) as a selling point. So Oracle’s multi-model revenue share is essentially their whole DB revenue, which by 2030 might shift more to cloud subscriptions but still the same product features.

In summary, the revenue/ARR tied to multi-API databases is growing rapidly in absolute and relative terms. Where in the mid-2010s it was minimal (since hardly any revenue came from multi-model DBs except MarkLogic), by mid-2020s we see multi-model players generating significant sales (Couchbase’s IPO, etc.) and big vendors deriving meaningful cloud revenue from them (Cosmos DB, etc.). By 2030, multi-API DB services could realistically account for on the order of half of all database market revenue if including both stand-alone multi-model DBs and the multi-model portions of traditional vendors’ revenue. However, it’s important to note that vendors do not typically break out “multi-API SKU revenue” explicitly, so this assessment is pieced together from market growth data and vendor strategy.

(Sources: Couchbase revenue $154.8M FY2023 ￼ – all from multi-model DB. NoSQL/multi-model market growth to $55B by 2030 ￼, showing multi-model capturing a growing share. Gartner MQ description of Oracle Autonomous DB as multimodel ￼ implies Oracle’s large DB revenue is tied to that capability. Industry analysis confirms multi-model DBs are a major area of innovation and growth ￼.)

Analyst Tracking of Multi-API Gateways by 2030

Industry analyst reports (from firms like Gartner, Forrester, IDC) play a big role in solidifying market terminology and evaluation criteria. As of mid-2020s, do analysts specifically call out “multi-API gateway” or “multi-model support” in their assessments, and will they by 2030?

Current Analyst View: Analysts already recognize multi-model capabilities as important, but they tend to use the term “multi-model database” rather than “multi-API gateway.” In Gartner’s Magic Quadrant for Cloud DBMS (2024), multi-model support is explicitly mentioned – for instance, Oracle’s solution is praised as a “robust, multimodel database service designed for diverse workloads” ￼. Gartner’s criteria for operational DBMS often include support for multiple data types (relational, document, graph, etc.) as a factor in completeness of vision. Forrester’s Wave for “Translytical Data Platforms” (which are systems that do both transactions and analytics, often multi-model) also highlights vendors that can handle various data models. So while they might not have a separate category called “Multi-API Gateways” (which sounds more like a feature), they embed that concept in their analysis of modern DB platforms. By 2025, Gartner had already essentially blurred the lines, covering relational and NoSQL under a unified Cloud DBMS Magic Quadrant. In their commentary, they note which vendors provide multimodal support. IDC in some reports has talked about the rise of multi-model databases as well.

However, at this time, analysts don’t treat “multi-API” as a standalone product segment; rather, it’s a capability within broader segments (Cloud DBMS, NoSQL, NewSQL, etc.). For example, Gartner didn’t have a Magic Quadrant titled “Multi-Model Databases” – instead, their Cloud DBMS MQ implicitly expects leading vendors to support multiple models. In evaluations, a lack of multi-model might be seen as a limitation. (Indeed, older single-model NoSQL vendors like Cassandra/DataStax or MongoDB might get dinged for not supporting other models, which perhaps motivated them to add features). Gartner also published feature comparisons (Critical Capabilities reports) that often include criteria like “Support for multiple data models” or similar.

By 2030, we predict that analyst reports will routinely track multi-API (multi-model) support as a checklist item for database platforms. It’s likely that by then, any leading DBMS will be expected to be multi-model, so the analysts might talk about it the way they talk about “scalability” or “security” – an assumed capability to evaluate how well it’s done rather than if it’s present. For instance, Gartner might explicitly mention “Multi-model (relational + JSON + graph) capabilities” in the strengths/weaknesses of each vendor. We might also see the emergence of terms like “unified data platform” in analysts’ language, which essentially means multi-API support.

One question is whether analysts create a separate category for this. Possibly, as multi-model becomes mainstream, they won’t need a separate Magic Quadrant just for multi-model DBs – it will be part of every general DBMS MQ. Already, they created the “Operational DBMS” category combining relational and non-relational. By 2030, if the concept of multi-model is ubiquitous, a distinct category might not be necessary. But they may have special reports on multi-model best practices, etc., or a Market Guide on “Federated Data Gateways” which could include multi-API gateways bridging databases (if the gateway concept extends to data virtualization tools).

We should note that analysts also track API management and data integration tools. “API gateways” in a generic sense are tracked in other contexts (for microservices, etc.). But a “multi-API data gateway” specifically for databases might still be a niche term. Instead, analysts will call it a capability of DBMS or perhaps call the products “multi-model data platforms.”

By 2030, we expect Gartner, Forrester, and others to explicitly highlight multi-model API support in their evaluation criteria, as it will align with user expectations in that era. Forrester’s report on translytical platforms already implicitly values having one platform for all workloads (translytical implies multi-model). Gartner in its “Top Trends in Data Management” will likely include something about unified data engines.

In essence, analysts in 2030 will likely consider a lack of multi-API support as a shortcoming. Conversely, any vendor that still offers only a single-model product might be categorized under a narrower niche (for example, a graph-only database might appear only in a specialized graph DB report, but in the main DBMS reports the leaders will all be those with broad API/model support). By 2030, it wouldn’t be surprising if Gartner’s Magic Quadrant commentary for every Leader mentions their multi-model versatility.

To answer the question succinctly: Yes, by 2030 analyst reports do track multi-API (multi-model) gateways as a distinct or crucial capability, although likely phrased as “multi-model support” rather than using the word gateway. Already by mid-2020s this is happening (e.g. Gartner highlighting multimodel in 2024 ￼). We did not find a reference to an analyst explicitly using the term “multi-API gateway” yet – they usually say “multimodel DBMS” – but the concept is the same.

One data point: Gartner in 2022/2023 had predictions like “80% of enterprises will unify their data architectures across multiple data models by 2030” (hypothetical example given trends). While our search found a Gartner quote about multimodal (which was about AI modalities, not databases, and thus not relevant ￼), the analogous prediction in data management is that multi-model is the future. In fact, Gartner’s analysts have stated that the distinctions between NoSQL and SQL will blur as relational systems add NoSQL capabilities and vice versa ￼. So by 2030, their reports will reflect that blurriness – likely treating “multi-model” as a given feature for top vendors.

Another angle: By 2030, there might be a new generation of analyst metrics – for example, tracking how many models/APIs a platform supports natively, or case studies tracked as part of scorecards (like “does the vendor have references for graph+document usage?”). If multi-API is mainstream, analysts could even have a scoring for “multimodel breadth” in their critical capabilities.

In conclusion, analysts are already on this path, and by 2030 multi-API gateway capability will be fully acknowledged and tracked. It may not be a separate Magic Quadrant but will be ingrained in the definition of an enterprise-grade DBMS. Any vendor lacking it would be seen as a niche or legacy player by that time.

(Sources: Oracle’s Gartner MQ excerpt shows multi-model noted as a strength ￼. Experts predict that distinctions between DB types will fade by ~2030 ￼, implying analysts will focus on unified capabilities. As of now, no separate “multi-API gateway” category exists, but multi-model is included in analyst evaluations, and by 2030 it will be a standard criterion.)

Counter-Evidence and Challenges: Persistence of Single-Model Databases & Skepticism

Despite the positive trends toward unified multi-API gateways, it’s important to acknowledge counter-evidence – not all industry movement or opinions favor this approach. There are notable challenges and dissenting perspectives:
	•	“Purpose-Built” Philosophy: The strongest counterpoint comes from the philosophy championed by AWS and others: Use the right tool for the right job, even if that means multiple databases. AWS publicly argues that a “one size fits all” database is not ideal. In a blog by AWS’s CTO Werner Vogels titled “A one size fits all database doesn’t fit anyone,” he emphasizes offering distinct database services for key-value, document, graph, etc., each optimized for its category ￼. AWS has built an entire portfolio of separate databases rather than one multi-model database. The reasoning is that specialized engines can be tuned for specific workloads and will outperform a jack-of-all-trades engine in those domains. This is borne out in some use-cases: for example, a pure graph database like Neo4j might handle complex graph traversals faster than a general multi-model that also does graph but with some compromises. Likewise, a dedicated time-series DB might be more efficient for time-series data than a general multi-model.
	•	Limited Usage of Features: Even when multi-model features exist, many customers don’t use them (or use only a subset). For instance, PostgreSQL has JSON and XML and even graph extensions, but a large portion of Postgres users use it just as a relational store with maybe a bit of JSON – effectively still a single-model usage. This calls into question how revolutionary the multi-model aspect has been for those users. If a feature isn’t used, its mere presence isn’t driving value. It implies that some organizations are content continuing with multiple databases or simply don’t have a need for multiple models in one app.
	•	Complexity and Maturity: Multi-API gateways add complexity to the system. Some multi-model databases historically struggled with maturity issues – early multi-model systems (e.g., OrientDB) encountered bugs and performance problems in certain modes, which made some companies hesitant. A multi-model DB has to be good enough at multiple things; if one aspect is weak, that could be a drawback. For example, a system might do documents well but have a rudimentary or slow graph traversal capability, leading the user to deploy a separate graph DB anyway. One survey (as described in the MoldStud article) suggests some multi-model solutions “may not perform optimally for certain model-specific operations compared to dedicated single-model databases” ￼. This is a known trade-off: a generalist vs a specialist.
	•	Polyglot Persistence Remains: Many large-scale architectures in practice still use polyglot persistence. For critical applications, an enterprise might use MongoDB for some part, Neo4j for another, and Elasticsearch for search, because those were the best-in-class choices – even if a multi-model DB existed that could theoretically replace all three, the risk or migration effort might not justify it. Cultural and team skill factors also play a role; organizations have DBAs and developers experienced in certain databases and may prefer to stick with them rather than adopt a new multi-model platform that requires new expertise across multiple data models.
	•	Vendor Strategy: Not all vendors are embracing multi-model wholeheartedly. For example, Amazon has by 2025 not released a single unified data store to supplant their individual ones. If by 2030 AWS still finds that offering separate services is successful (and customers manage integration at the application level or use AWS glue services), that’s counter to the idea of every platform shipping a unified gateway. Similarly, some open-source communities (like the core PostgreSQL community) might resist adding too many non-relational features that could bloat or destabilize the system; they might rely on external projects for that. This suggests some platforms might remain primarily single-model by design even in 2030, carving out niches or relying on extension ecosystems.
	•	Analyst Caution: Analysts might caution that while multi-model is promising, it isn’t a panacea. For example, a Gartner report might warn that “enterprises should be wary of the ‘all-in-one’ database claim and ensure that a multi-model DBMS meets their specific needs as well as dedicated solutions would.” As of now, Gartner’s advice often is to adopt multi-model databases for appropriate use cases but also to continue using specialized systems where they make sense ￼ ￼. The coexistence of polyglot and multi-model is acknowledged: “relational and NoSQL databases often coexist… and sometimes even converge” ￼ – but not fully converge in all scenarios.
	•	Economic/Practical Limits: Some multi-model databases might cost more (licensing or resource usage) than using tailored stores for each piece. Or an organization might have one part of an application that is so performance-sensitive (say, a full-text search across huge logs) that they will use Elasticsearch regardless, even if their main DB is multi-model with some search feature. This selective adoption could persist.

Counter-Evidence Summary: We cannot ignore that a substantial number of enterprises will likely continue to use multiple databases for different purposes through 2030. For these, a unified gateway isn’t a priority or perhaps isn’t trusted to handle all needs. The existence of AWS’s strategy and its success is evidence that the market has room for multiple approaches. In 2025, AWS has the largest cloud database business with no unified gateway product – strong evidence that many customers are fine with (or even prefer) separate databases for separate tasks. This may still hold in 2030 for a segment of customers, especially those at the cutting edge of scale who choose specialized tools for each job (e.g., a separate graph database for graph analytics, separate time-series DB for metrics, etc., integrated at the application level or via data pipelines).

Moreover, some use cases don’t require multi-model at all (a simple e-commerce application might do perfectly well with just a relational DB and never need a graph or a JSON store). For those, the push for multi-API might be moot. Vendors will still supply lightweight, single-purpose options (perhaps as embedded databases, etc.) for simplicity in such scenarios.

Thus, the transition to multi-API gateways, while strong, may be slower or less uniform than optimistic predictions assume. We might find in 2030 that, say, 30% of workloads still use purpose-built single-model databases exclusively (number for illustration), and that analysts continue to talk about how to integrate multiple databases – meaning multi-model did not entirely eliminate the need for multiple systems.

Conclusion of Counterpoint: The multi-API gateway revolution is real but not absolute. The “best database for each workload” argument continues to resonate ￼, and not all vendors or customers are convinced that one unified system can truly replace all specialized ones. Therefore, while multi-model will be mainstream, single-model databases will co-exist and remain relevant. Analyst reports by 2030 might celebrate multi-model capabilities but also note that some leading vendors (perhaps even AWS) succeed with a portfolio of purpose-built databases, tracking those as an alternative strategy.

In essence, the counter-evidence suggests the penetration of multi-API gateways could be high but not 100% by 2030, and their advantages may come with trade-offs that keep the “polyglot persistence” approach alive longer than one might expect.

(Sources: AWS’s emphasis on purpose-built DBs – “developers now have the choice of relational, key-value, document, graph… Each of these databases solve a specific problem” ￼ – underlines a contrary approach. Multi-model performance trade-offs noted in analysis ￼. Coexistence of relational & NoSQL (polyglot) acknowledged in industry discussions ￼. These show that one unified gateway hasn’t universally replaced multiple databases yet, and perhaps won’t for every scenario.)

⸻

Sources:
	1.	Rapydo (2025) – “The Rise of Multi-Model Databases in Modern Architectures” (blog) – notes that multi-model DBs are among the fastest-growing categories and discusses vendor landscape ￼ ￼.
	2.	MoldStud Research (2025) – “NoSQL Database Trends – Embracing Multi-Model” – cites Gartner: “by 2025, over half of enterprise data initiatives will leverage multi-model capabilities…” ￼ and that companies report 40% less time on data management with these solutions ￼; also 75% of orgs use a mix of DB types ￼.
	3.	PAT Research (2024) – “Top 7 Multi-Model Databases” – lists leading multi-model DB platforms (MarkLogic, ArangoDB, OrientDB, Cosmos DB, etc.) ￼.
	4.	Oracle/Gartner (2024) – Gartner Magic Quadrant for Cloud DBMS (excerpt via Oracle) – highlights Oracle Autonomous DB as a “robust, multimodel database service for diverse workloads” ￼.
	5.	ArangoDB Case Study – Kevin Bayes, CTO quote on consolidating search/graph/document in one DB for better performance and simplicity ￼.
	6.	Couchbase/CloudWars (2023) – Couchbase VP on customer survey: clients bought it for performance and flexibility (consolidating databases); multi-model support means multiple data types in one DB ￼.
	7.	Couchbase Whitepaper – “10 Common NoSQL Use Cases” (Domino’s case) – “multi-model features allowed Domino’s to… search and analyze data within the same system” ￼.
	8.	AWS “All Things Distributed” blog (2018) – Werner Vogels on purpose-built DBs: multiple specialized DBs for different data models, “the categories of nonrelational DBs continue to grow… developers have choice of relational, key-value, document, graph… Each solves a specific problem.” ￼.
	9.	Gartner/rapydo (2025) – prediction that by 2035 multi-model DBs may make “NoSQL” term obsolete; convergence of models expected ￼.
	10.	Market Forecast (Mordor Intelligence) – NoSQL DB market to $55.5B by 2030 from $15B in 2025 ￼, indicating rapid growth of multi-model segment.